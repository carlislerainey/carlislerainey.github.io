{
  "hash": "023e0e023479a94d0bad2b902494e020",
  "result": {
    "markdown": "---\ntitle: \"Equivalence Tests Using {marginaleffects}\"\nsubtitle: \"Reproducing the Clark and Golder (2006) Example from Rainey (2014)\"\nauthor: \"Carlisle Rainey\"\ndate: \"2023-08-18\"\ncategories: [hypothesis tests, confidence intervals, equivalence tests, negligible effects, computing, R, marginaleffects]\ndescription: \"In this post, I try out the {marginaleffects} package to conduct two one-sided tests (TOSTs) to test a hypothesis of a negligible effect (i.e., equivalence testing).\"\nimage: \"rainey-2014-cg-example.png\"\nreference-location: margin\ntoc: false\ntwitter-card:\n  card-style: summary_large_image\n  image: \"twitter-card.png\"\n  title: \"Equivalence Tests with {marginaleffects}\"  # less than 55 chars\n  description: \"Reproducing the Clark and Golder (2006) example from Rainey (2014)\"  # less than 125 chars\nopen-graph:   \n  image: \"twitter-card.png\"\n  title: \"Equivalence Tests with {marginaleffects}\"  # less than 55 chars\n  description: \"Reproducing the Clark and Golder (2006) example from Rainey (2014)\"  # less than 125 chars\ncode-annotations: hover\ncode-fold: false\nexecute: \n  cache: false\ndraft: false\n---\n\n\n## Background on arguing for a negligible effect\n\nFirst, a bit of background on the paper and the idea of hypothesizing that a variable \"has no effect.\"\n\nI remember sitting in a talk as a first-year graduate student, and the speaker said something like: \"I expect no effect here, and, just as I expected, the difference is not statistically significant.\" I was a little bit taken aback---of course, that's not a compelling argument for a null effect. But I saw this approach taken again and again in published work. \n\nMy first publication was an *AJPS* article ([Rainey 2014](https://doi.org/10.1111/ajps.12102)) explaining why this doesn't work well and how to do it better. \n\nHere's what I wrote in that paper: \n\n> Hypothesis testing is a powerful empirical argument not because it shows that the data are consistent with the research hypothesis, but because it shows that the data are inconsistent with other hypotheses (i.e., the null hypothesis). However, researchers sometimes reverse this logic when arguing for a negligible effect, showing only that the data are consistent with \"no effect\" and failing to show that the data are inconsistent with meaningful effects. When researchers argue that a variable has \"no effect\" because its confidence interval contains zero, they take no steps to rule out large, meaningful effects, making the empirical claim considerably less persuasive ([Altman and Bland 1995](https://doi.org/10.1136/bmj.311.7003.485); [Gill 1999](https://doi.org/10.1177/106591299905200309); [Nickerson 2000](https://psycnet.apa.org/doi/10.1037/1082-989X.5.2.241)). \n\nBut here's a critical point, it's impossible to reject every hypothesis except *exactly* no effect. Instead, the researcher must define a range of substantively \"negligible\" effects. The researcher *can* reject the null hypothesis that the effect falls outside this range of negligible effects. However, this requires a substantive judgement about those effects that are negligible and those that are not.\n\nHere's what I wrote: \n\n> Researchers who wish to argue for a negligible effect must precisely define the set of effects that are deemed \"negligible\" as well as the set of effects that are \"meaningful.\" This requires defining the smallest substantively meaningful effect, which I denote as $m$. The definition must be debated by substantive scholars for any given context because the appropriate $m$ varies widely across applications.\n\n## Clark and Golder (2006) \n\n[Clark and Golder (2006)](https://doi.org/10.1177/0010414005278420) offer a nice example of this sort of hypothesis. I'll refer you there and to [Rainey (2014)](https://doi.org/10.1111/ajps.12102) for a complete discussion of their idea, but I'll motivate it briefly here.\n\nExplaining why a country might have only a few (i.e., two) parties, Clark and Golder write:\n\n> First, it could be the case that the demand for parties is low because there are few social cleavages. In this situation, there would be few parties whether the electoral institutions were permissive or not. Second, it could be the case that the electoral system is not permissive. In this situation, there would be a small number of parties even if the demand for political parties were high. Only a polity characterized by both a high degree of social heterogeneity and a highly permissive electoral system is expected to produce a large number of parties. (p. 683)\n\nThus, they expect that electoral institutions won't matter in socially homogenous systems. And they expect that social heterogeneity won't matter in electoral systems that are not permissive.\n\n## Reproducing Clark and Golder (2006) \n\nBefore computing their specific quantities of interest, let's reproduce their regression model. Here's their table that we're trying to reproduce.\n\n![](clark-golder-2006-table2.png)\n\nAnd here's a reproduction of their estimates using the `cg2006` data from the [{crdata} package](http://www.carlislerainey.com/crdata/) on GitHub.^[Run `?crdata::cg2006` for detailed documentation of this data set.]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(sandwich)\nlibrary(modelsummary)\n\n# install my data packages from github\ndevtools::install_github(\"carlislerainey/crdata\")  # only updates if newer version available\n\n# load clark and golder's data set\ncg <- crdata::cg2006\n\n# reproduce their estimates\nf <- enep ~ eneg*log(average_magnitude) + eneg*upper_tier + en_pres*proximity\nfit <- lm(f, data = cg)\n\n# cluster-robust standard errors\nSigma_hat <- vcovCL(fit, cluster = ~ country, type = \"HC1\")\n\n# regression table\nmodelsummary(fit, vcov = Sigma_hat, fmt = 2, shape = term ~ model + statistic)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \"> (1)</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Est. </th>\n   <th style=\"text-align:center;\"> S.E. </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> 2.92 </td>\n   <td style=\"text-align:center;\"> 0.35 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> eneg </td>\n   <td style=\"text-align:center;\"> 0.11 </td>\n   <td style=\"text-align:center;\"> 0.14 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> log(average_magnitude) </td>\n   <td style=\"text-align:center;\"> 0.08 </td>\n   <td style=\"text-align:center;\"> 0.23 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> upper_tier </td>\n   <td style=\"text-align:center;\"> −0.06 </td>\n   <td style=\"text-align:center;\"> 0.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> en_pres </td>\n   <td style=\"text-align:center;\"> 0.26 </td>\n   <td style=\"text-align:center;\"> 0.15 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> proximity </td>\n   <td style=\"text-align:center;\"> −3.10 </td>\n   <td style=\"text-align:center;\"> 0.46 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> eneg × log(average_magnitude) </td>\n   <td style=\"text-align:center;\"> 0.26 </td>\n   <td style=\"text-align:center;\"> 0.17 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> eneg × upper_tier </td>\n   <td style=\"text-align:center;\"> 0.06 </td>\n   <td style=\"text-align:center;\"> 0.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> en_pres × proximity </td>\n   <td style=\"text-align:center;\"> 0.68 </td>\n   <td style=\"text-align:center;\"> 0.23 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nSuccess!\n\nThey use `averge_magnitude` to measure the permissiveness of the electoral system and `eneg` to measure social heterogeneity.\n\n## Using `comparisons()` to compute the effects\n\nNow let's compute the two quantities of interest. Clark and Golder argue for two negligible effects, which I make really concrete below.\n\n- **Hypothesis 1** Increasing the effective number of ethnic groups from the 10th percentile (1.06) to the 90th percentile (2.48) will not lead to a substantively meaningful change in the effective number of political parties when the district magnitude is one.\n- **Hypothesis 2** Increasing the district magnitude from one to seven will not lead to a substantively meaningful change in the effective number of political parties when the effective number of ethnic groups is one.\n\nAnd comparing the U.S. and the U.K., I argue that the smallest substantively interesting effect is 0.62. In [Rainey (2014)](https://doi.org/10.1111/ajps.12102), I made the plot below. I want to reproduce it with {marginaleffects}.\n\n![](rainey-2014-cg-example.png)\n\nThese differences (and the 90% CIs) are really easy to compute using {marginaleffects}!^[I'm only doing Clark and Golder's original results, not any of the robustness checks.]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(marginaleffects)\n\n# the smallest substantively interesting effect\nm <- 0.62\n\n# a data frame setting the values of the \"other\" variables\nX_c <- data.frame(\n  eneg = 1.06,  # low value\n  average_magnitude = 1,  # low value\n  upper_tier = 0,\n  en_pres = 0, \n  proximity = 0\n)\n\n# compute the comparison for eneg\neneg_comp <- comparisons(fit,\n                    vcov = Sigma_hat,\n                    newdata = X_c, \n                    variables = list(\"eneg\" = c(1.06, 2.48)), # low to high value\n                    conf_level = 0.90)\n\n# compute the comparison for average magnitude\nmag_comp<- comparisons(fit,\n                    vcov = Sigma_hat,\n                    newdata = X_c, \n                    variables = list(\"average_magnitude\" = c(1, 7)), # low to high value\n                    conf_level = 0.90)\n```\n:::\n\n\nNow we can just plot the 90% CIs with `ggplot()` and check whether the entire interval falls inside the bounds.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\n\n# bind the comparisons together and plot\ncomp <- bind_rows(eneg_comp, mag_comp)\nggplot(comp, aes(x = estimate,\n                 xmin = conf.low,\n                 xmax = conf.high, \n                 y = term)) + \n  geom_vline(xintercept = c(-m, m), linetype = \"dashed\") + \n  geom_errorbarh() + \n  geom_point() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nIn this case, we conclude that social heterogeneity (`eneg`) has a negligible effect because the 90% CI only contains substantively negligible values. However, the 90% CI for district magnitude (`average_magnitude`) contains substantively negligible and meaningful values, so we cannot reject the null hypothesis of a meaningful effect.\n\n## Computing the TOST *p*-values using `hypotheses()`\n\nIt's then almost trivial to use the `hypotheses()` function to compute the TOST *p*-values.^[Note this warning from `?hypotheses()`: *Warning #2: For hypothesis tests on objects produced by the marginaleffects package, it is safer to use the hypothesis argument of the original function. Using hypotheses() may not work in certain environments, in lists, or when working programmatically with apply style functions.*]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# hypothesis tests\nhypotheses(eneg_comp, equivalence = c(-m, m))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Term    Contrast Estimate Std. Error    z Pr(>|z|)   S   2.5 % 97.5 %\n eneg 2.48 - 1.06    0.158      0.101 1.56    0.118 3.1 -0.0402  0.357\n p (NonSup) p (NonInf) p (Equiv) eneg average_magnitude upper_tier en_pres\n     <0.001     <0.001    <0.001 1.06                 1          0       0\n proximity\n         0\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, eneg, average_magnitude, upper_tier, en_pres, proximity, enep, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n```\n:::\n\n```{.r .cell-code}\nhypotheses(mag_comp, equivalence = c(-m, m))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n              Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 %\n average_magnitude    7 - 1    0.696      0.113 6.16   <0.001 30.3 0.474  0.917\n p (NonSup) p (NonInf) p (Equiv) eneg average_magnitude upper_tier en_pres\n      0.748     <0.001     0.748 1.06                 1          0       0\n proximity\n         0\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, eneg, average_magnitude, upper_tier, en_pres, proximity, enep, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv \n```\n:::\n:::\n\n\nChecking that the 90% CIs fall within the bounds created by the smallest substantively-meaningful effect is equivalent to checking whether the TOST *p*-value (i.e., the `p(Equiv)` column) is less than 0.05, so our conclusions are (and must be) identical.\n\n## Final thoughts\n\n1. {marginaleffects} is a great package. I think it's the first package in which the syntax matches the way I think about computing quantities of interest. That said, this is just my first try at it. But I'm very impressed so far.\n1. The {marginaleffects} [book](https://marginaleffects.com) has a whole [chapter](https://marginaleffects.com/articles/equivalence.html) on equivalence tests. My only caution is that there is a mismatch between 95% confidence intervals and equivalence tests. By default, {marginaleffects} reports a 95% CI, even when producing a *p*-value for an equivalence test. However, the 90% confidence interval correspondents to a size-5% equivalence test. So if you're using {marginaleffects} to do equivalence tests, I recommend setting `conf_level = 0.90`.^[I would make a similar point about one-sided tests as well, but that's less correct, because it should be a *one-sided* 95% CI.]\n1. For a more recent example, Jake Jares and Neil Malhotra have a [new paper](https://jakejares.com/uploads/Jares%20and%20Malhotra%20%282023%29%20--%20Policy%20Impact%20and%20Voter%20Mobilization.pdf) that discusses negligible effects and hypothesis tests in a way that I find clear and compelling. It's an excellent model to follow. See pp. 26-31. They \"show that improved compensation outcomes had negligible impacts on Republican farmers' midterm turnout and campaign contributions, even though such variation in benefits significantly affected whether farmers viewed the intervention as helpful.\"\n\n\n## Complete code\n\nTo make this easy to reproduce, here's the complete code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(sandwich)\nlibrary(modelsummary)\nlibrary(marginaleffects)\n\n# install my data packages from github\ndevtools::install_github(\"carlislerainey/crdata\")  # only updates if newer version available\n\n# load clark and golder's data set\ncg <- crdata::cg2006\n\n# reproduce their estimates\nf <- enep ~ eneg*log(average_magnitude) + eneg*upper_tier + en_pres*proximity\nfit <- lm(f, data = cg)\n\n# cluster-robust standard errors\nSigma_hat <- vcovCL(fit, cluster = ~ country, type = \"HC1\")\n\n# regression table\nmodelsummary(fit, vcov = Sigma_hat, fmt = 2, shape = term ~ model + statistic)\n\n# the smallest substantively interesting effect\nm <- 0.62\n\n# a data frame setting the values of the \"other\" variables\nX_c <- data.frame(\n  eneg = 1.06,  # low value\n  average_magnitude = 1,  # low value\n  upper_tier = 0,\n  en_pres = 0, \n  proximity = 0\n)\n\n# compute the comparison for eneg\neneg_comp <- comparisons(fit,\n                         vcov = Sigma_hat,\n                         newdata = X_c, \n                         variables = list(\"eneg\" = c(1.06, 2.48)), # low to high value\n                         conf_level = 0.90)\n\n# compute the comparison for average magnitude\nmag_comp<- comparisons(fit,\n                       vcov = Sigma_hat,\n                       newdata = X_c, \n                       variables = list(\"average_magnitude\" = c(1, 7)), # low to high value\n                       conf_level = 0.90)\n\n# bind the comparisons together and plot\ncomp <- bind_rows(eneg_comp, mag_comp)\nggplot(comp, aes(x = estimate,\n                 xmin = conf.low,\n                 xmax = conf.high, \n                 y = term)) + \n  geom_vline(xintercept = c(-m, m), linetype = \"dashed\") + \n  geom_errorbarh() + \n  geom_point() \n\n# hypothesis tests (TOSTs)\nhypotheses(eneg_comp, equivalence = c(-m, m))\nhypotheses(mag_comp, equivalence = c(-m, m))\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}