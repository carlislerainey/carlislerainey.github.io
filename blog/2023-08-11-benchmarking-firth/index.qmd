---
title: "Benchmarking Firth's Logit: {brglm2} versus {logistf}"
subtitle: "logistf() is really fast"
author: "Carlisle Rainey"
date: "2023-08-11"
categories: [logistic regression, small samples, Firth, computing, R]
description: "In this post, I benchmark the brglm2 and logistf packages for fitting logistic regression models with Firth's penalty. "
toc: false
code-annotations: hover
draft: false
bibliography: references.bib
---

## Firth's Logit

I like Firth's logistic regression model [@firth1993]. I talk about that in @rainey2021 and [this Twitter thread](https://twitter.com/carlislerainey/status/1686389777225113601). @kosmidis2021 offer an excellent, recent follow-up as well.

I'll refer you to the papers for a careful discussion of the benefits, but Firth's penalty reduces the bias *and variance* of the logit coefficients.

## Goals for Benchmarking

In this post, I want to compare the brglm2 and logistf packages. Which fits logistic regression models with Firth's penalty the fastest?

These packages both fit the models almost instantly, so there is no practical difference when fitting just one model. But large Monte Carlo simulations (or perhaps bootstraps), small differences might add up to a substantial time difference.

Here, I benchmark the two packages for fitting logistic regression models with Firth's penalty in a *small sample*--the results might not generalize to a larger sample. The data set comes from @weisiger2014 (see `?crdata::weisiger2014`). It has only 35 observations.

You can find the benchmarking code as a [GitHub Gist](https://gist.github.com/carlislerainey/8bf23a322252bead64d0a07391f7383d).

## Computer

Here's the info on my machine. 

```{r} 
system("sysctl -n machdep.cpu.brand_string", intern = TRUE)
```

## Benchmarking

I benchmark four methods here.

1. A vanilla `glm()` logit model.
1. A Firth's logit via brglm2 by supplying `method = brglm2::brglmFit` to `glm()`.
1. A Firth's logit via logistf via `logistf()` using the default settings. 
1. A Firth's logit via logistf via `logistf()` with the argument `pl = FALSE`. This argument is important because it skips hypothesis testing using profile likelihoods, which are computationally costly.


```{r}
#| message: false

# install crdata package to egt weisiger2014 data set
remotes::install_github("carlislerainey/crdata")

# load packages
library(tidyverse)
library(brglm2)
library(logistf)
library(microbenchmark)


# load data
weis <- crdata::weisiger2014

# rescale weisiger2014 explanatory variables using arm::rescale()
rs_weis <- weis %>%
  mutate(across(polity_conq:coord, arm::rescale)) 

# create functions to fit models
f <- resist ~ polity_conq + lndist + terrain + soldperterr + gdppc2 + coord
f1 <- function() {
  glm(f, data = rs_weis, family = "binomial")
}
f2 <- function() {
  glm(f, data = rs_weis, family = "binomial", method = brglmFit)
}
f3 <- function() {
  logistf(f, data = rs_weis)
}
f4 <- function() {
  logistf(f, data = rs_weis, pl = FALSE,
          control= logistf.control(lconv=1e-06))
}

# do benchmarking
bm <- microbenchmark("regular glm()" = f1(), 
               "brglm2" = f2(), 
               "logistf (default)" = f3(),
               "logistf (w/ pl = FALSE)" = f4(),
               times = 100) 

print(bm)
```

In short, logistf is slower than brglm2, but only because it computes the profile likelihood *p*-values by default. Once we skip those calculations using `pl = FALSE`, logistf is *much* faster. On average, it's faster than `glm()`, because `glm()` has the occasional *really* slow computation. 

Here's a plot showing the computation times of the four fits. Remember that all of these are computed practically instantly, so it only makes a difference when the fits are done thousands of times, like in a Monte Carlo simulation. 

```{r}
# plot times
bm %>%
  group_by(expr) %>%
  summarize(avg_time = mean(time)*10e-5) %>%  # convert to milliseconds
  ggplot(aes(x = fct_rev(expr), y = avg_time)) + 
  geom_col() + 
  labs(x = "Method", 
       y = "Avg. Time (in milliseconds)") + 
  coord_flip()
```

# Follow-Up Notes

Ioannis Kosmidis made me aware of two things. 

1. logistf has a C++ backend (thus explaining the speed).
1. brglm2 is written entirely in R. He noted that a new version is coming out soon that might be substantially faster. (brglm2 is also more general; it supports a variety of models and corrections).
