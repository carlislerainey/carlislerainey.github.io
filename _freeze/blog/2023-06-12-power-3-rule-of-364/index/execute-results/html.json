{
  "hash": "286035807427b9fe0bf99af45df98121",
  "result": {
    "markdown": "---\ntitle: \"Power, Part III: The Rule of 3.64 for Power's Key Ratio\"\nsubtitle: \"Simple, Actionable Guidelines for Statistical Power\"\nauthor: \"Carlisle Rainey\"\ndate: \"2023-06-08\"\ncategories: [statistical power, hypothesis tests, power analysis, methodology, confidence intervals, computing, R]\ndescription: \"Power is an abstract quantity. It's easy to understand what it means, but harder to think about how to manipulate it. I encourage students to think about the ratio of the true effect to the standard error. I explain why trying to make the ratio at least 2.48 is equivalent to a target power of 80%. But you want to almost always reject the null, so you should shoot for a ratio of 3.64. These guideless help you build a bit of actionable intuition about statistical power.\"\nimage: \"twitter-card.png\"\nreference-location: margin\ntoc: false\ntwitter-card:\n  card-style: summary_large_image\n  image: \"twitter-card.png\"\n  title: \"The Rule of 3.64\"  # less than 55 chars\n  description: \"I develop the intuition of simple, actionable guidelines for statistical power.\"  # less than 125 chars\nopen-graph:   \n  image: \"twitter-card.png\"\n  title: \"The Rule of 3.64\"  # less than 55 chars\n  description: \"I develop the intuition of simple, actionable guidelines for statistical power.\"  # less than 125 chars\ncode-annotations: hover\ncode-fold: true\nexecute: \n  cache: true\ndraft: true\n---\n\n\n## Background\n\nI've wrapped up the argument that you should pursue statistical power in your experiments. In sum, you should do it for *you* (not a future Reviewer 2) and you shouldn't see confidence intervals nestle consistently against zero.\n\n1. [\"Power Is For You, Not For Reviewer 2\"](/blog/2023-05-22-power-1-for-you-not-reviewer-2)\n1. [\"What Do Confidence Intervals From Well-Powered Studies Look Like?\"](/blog/2023-05-25-power-2-what-do-confidence-intervals-look-like)\n\nIn this post, I'd like to develop the intuition for power calculations, two helpful guidelines, and one implication.\n\nMain takeaway: You need the ratio of the true effect and the standard error to be more than 3.64.\n\n## Starting Point: The Sampling Distribution\n\nWhen you run one experiment, you realize *one* of many possible patterns of randomization. This particular realization produces a single **estimate** of the treatment effect from a *distribution* of possible estimates. The distribution of possibilities is called a \"**sampling distribution**.\" \n\nThus, we can think of the estimate as a random variable and its distribution as the sampling distribution. The sampling distribution is key to everything I do in this post, so let's spend some time with it. \n\nLet's imagine that we did the exact same study 50 times. Let's say that we computed a difference-in-means in dollars (\\$) donated.^[I just want an easy-to-use unit here, and dollars meets that criteria. Other units work fine, too.] I refer to this difference-in-means as the estimated treatment effect. It is the estimate of the average treatment effect (in \\$). This estimate will vary across the many possible patterns of randomization because each pattern puts different respondents in the treatment and control group.\n\nWe can visualize this with ggnaminate. We can imagine each iteration of the study as producing a particular estimate. We continue to repeat the study and collect the estimates. Eventually, we can produce a histogram from this collection of estimates. This histogram represents the sampling distribution and is fundamental to the calculations that follow. The figure belows shows how we might collect the points into a histogram.\n\n\n::: {.cell .column-screen-inset-right hash='index_cache/html/unnamed-chunk-1_163f8939340f7b3b0baeede37d900593'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(gganimate)\nlibrary(magick)\n\n# gif pars\nduration <- 24 # must be even\nfps <- 25\nnframes <- duration*fps\nscale <- 2.5\nwidth <- 8\nheight <- 6\nres <- 125\n\n# study parameters\ntrue_effect <- 1\nse <- 0.4\n\n# number of times to repeat the study\nn_studies <- 50 # nframes\n\n# create a data frame of confidence intervals\nests <- tibble(study_id = 1:n_studies, \n               est = c(rnorm(n_studies, true_effect, se))) %>%\n  mutate(reject_null = ifelse(est - 1.64*se > 0, \"Yes\", \"No\"))\n\n# add two things to the data frame of confidence intervals\n# 1. an initial row with study_id = 1 and est = NA so that \n#    the plot starts empty (gganimate would start with the \n#    first observation in place otherwise).\n# 2. a group variable that defines the row. This is the same\n#    as the study_id, except the dummy row from (1) and the \n#    actual first row have different groups.\nanimate_data <- bind_rows(\n  tibble(study_id = 1, est = NA),  # study_id = 1, est = NA\n  ests                             # actual cis\n) %>%\n  mutate(group = 1:n()) \n\nsplit_animate_data <- animate_data %>%        # group (row index)\n  split(.$group) %>%\n  accumulate(~ bind_rows(.x, .y)) %>% \n  bind_rows(.id = \"frame\") %>% \n  mutate(frame = as.integer(frame))\n\n\nse_lines <- tribble(\n  ~se_, ~label, ~chance, ~ch_loc_,  # trailing _ means not rescaeld to study se\n  0, \"True Effect\", NA, NA,\n  1, \"+1 SE\", scales::percent(pnorm(1) - pnorm(0), accuracy = 1), 0.5,\n  2, \"+2 SE\", scales::percent(pnorm(2) - pnorm(1), accuracy = 1), 1.5,\n  3, \"+3 SE\", scales::percent(pnorm(3) - pnorm(2), accuracy = 1), 2.5,\n  -1, \"-1 SE\", scales::percent(pnorm(0) - pnorm(-1), accuracy = 1), -0.5,\n  -2, \"-2 SE\", scales::percent(pnorm(-1) - pnorm(-2), accuracy = 1), -1.5,\n  -3, \"-3 SE\", scales::percent(pnorm(-2) - pnorm(-3), accuracy = 1), -2.5,\n) %>%\n  mutate(ch_loc = ch_loc_*se + true_effect,\n         se = se_*se + true_effect)\n\n# start with a ggplot\ngg1 <- ggplot(animate_data, aes(x = est, \n                               y = study_id,\n                               group = group)) + \n  geom_vline(data = se_lines, aes(xintercept = se, \n                                  color = -dnorm(se_)), linetype = \"dashed\") + \n  geom_label(data = se_lines, aes(x = se, y = n_studies + 2, label = label, group = NULL, color = -dnorm(se_))) + \n  geom_text(data = se_lines, aes(x = ch_loc, y = 4, label = chance, group = NULL)) + \n  geom_point(aes(color = -dnorm((est- true_effect)/se)),\n             size = 3) + \n  geom_rug(sides = \"b\", \n           aes(x = est, \n               color = -dnorm((est- true_effect)/se)), \n           alpha = 0.5, \n           length = unit(0.025, \"npc\")) + \n  theme_bw() + \n  theme(panel.grid.minor.y = element_blank()) + \n  labs(x = \"Estimate of Effect\",\n       y = \"Study Number\") +\n  theme(legend.position = \"none\")\n\n# add dyamics to the plot\ngg1_anim <- gg1 +  \n  transition_states(states = group) + \n  # how points enter\n  enter_drift(y_mod = 10) +\n  enter_grow() +\n  enter_fade() + \n  # how points exit/remain\n  exit_fade(alpha = 0.5) +\n  exit_shrink(size = 1) + \n  shadow_mark(alpha = 0.5) \n\ngg1_gif<- animate(gg1_anim, nframes = nframes, duration = duration, width = width, height = height, units = \"in\", res = res)\nanim_save(\"gg1.gif\")\ngg1_mgif <- image_read(\"gg1.gif\")\n\n\n## plot 2: histogram\n# start with a ggplot\ngg2 <- ggplot(split_animate_data, aes(x = est, group = frame)) + \n  geom_histogram(binwidth = se, boundary = true_effect, fill = \"grey\") + \n  geom_vline(data = se_lines, aes(xintercept = se, \n                                  color = -dnorm(se_)), linetype = \"dashed\") + \n  geom_label(data = se_lines, aes(x = se, y = Inf, label = label, group = NULL, color = -dnorm(se_)), vjust = 1.5) + \n  geom_label(data = se_lines, aes(x = ch_loc, y = 0, label = chance, group = NULL), vjust = -1) + \n  #geom_density(linewidth = 2) + \n  geom_rug(sides = \"b\", \n           aes(x = est, \n               color = -dnorm((est- true_effect)/se)), \n           alpha = 0.5, \n           length = unit(0.025, \"npc\")) + \n  theme_bw() + \n  labs(x = \"Estimate of Effect\",\n       y = \"Count\") + \n  theme(legend.position = \"none\")\n\n# add dyamics to the plot\ngg2_anim <- gg2 +  \n  transition_states(states = frame)\n\ngg2_gif<- animate(gg2_anim, nframes = nframes, duration = duration, width = width, height = height, units = \"in\", res = res)\nanim_save(\"gg2.gif\")\ngg2_mgif <- image_read(\"gg2.gif\")\n\n\n\nnew_gif <- image_append(c(gg1_mgif[1], gg2_mgif[1]), stack = FALSE)\nfor(i in 2:nframes){\n  combined_gif <- image_append(c(gg1_mgif[i], gg2_mgif[i]), stack = FALSE)\n  new_gif <- c(new_gif, combined_gif)\n}\nnew_gif\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.gif)\n:::\n\n```{.r .cell-code}\nfile.remove(\"gg1.gif\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nfile.remove(\"gg2.gif\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nBefore the study, we can predict two features of this sampling distribution.\n\n1. First, it will usually have a bell-shaped, normal distribution. \n2. Second, we can predict the standard deviation of this distribution with good accuracy before conducting a single study and excellent accuracy after just one study. We call the standard deviation of the sampling distribution the **standard error** or **SE**.\n\nFor our purposes, then, we can describe the sampling distribution as normally distributed with an assumed mean and SD. The mean is the assumed true effect and the SD is the well-predicted SE.\n\nThis is the key claim: **In order to build power into your experiment, you must build certain properties into the sampling distribution.**\n\nThe design of your experiment will not affect the normality of the sampling distribution, but it will change the true effect and the SE. Changing the true effect and the SE will change the power. \n\n## Thinking about True Effect and Standard Error as *Targets*\n\nI'm leaving aside how to predict the standard error of the experiment or choose the true effect. This post is about the *target* standard error and true effect.\n\nPredicting the standard error is a mechanical process mixed with a little guesswork.^[I'll suggest two methods I like. First, use $\\text{predicted SE} \\frac{SD of same outcome in different data set}{2 \\sqrt{\\text{sample size}}}$. I like to confirm this estimate with a small pilot. I sample observations from this pilot dataset, run the full analysis, and confirm that my prediction is close, and make any needed adjustments.] Choose a true effect is a mostly substantive decision.^[[Cyrus Samii](https://twitter.com/cdsamii/status/1661091885580992517?s=20) likes to use the MME, I like a conservatively choosen guess of what the effect actually is.]\n\n\nBut instead of talking about a target power, I like to talk about a target standard error (given a true effect) or a target true effect (given a standard error)---power is just not a very intuitive quantity.\n\nTo understand how the true effect and the SE relate to power, we need to introduce the confidence interval.\n\n## Testing with Confidence Intervals\n\nI like to use 90% confidence intervals to test hypotheses (see [Rainey 2014](http://www.carlislerainey.com/papers/nme.pdf) and [Rainey 2015](http://www.carlislerainey.com/papers/meaningful.pdf)). In short, 90% confidence intervals correspond to one-tailed tests with size 0.05 and equivalence tests with size 0.05.] The formula for a 90% CI is $\\text{estimate} \\pm 1.64\\text{SE}$. That is, we put \"arms\" around our estimate---one to the left and another to the right. Each arm is 1.64 standard errors long. \n\nI'll assume we have a one-sided research hypothesis that suggests a positive effect. If the lower bound ($\\text{estimate} - 1.64\\text{SE}$) is less than zero, then we fail to reject the null hypothesis. If this lower bound is greater than zero, then we reject the null hypothesis.^[This is equivalent to a *z*-test in a standard hypothesis testing framework using a *p*-value of less than 0.05 as the threshold for rejecting the null hypothesis.] \n\nThis focus on *testing* rather than *estimation* changes the nature of the sampling distribution. Rather than an estimate along a continuous range, we get a binary outcome: either (1) reject the null hypothesis or (2) fail to reject the null hypothesis.\n\nBut the sampling distribution of estimates and the associated outcomes of tests are closely related. In particular, the logic of the test implies that *if the estimate falls less than 1.64 SEs above zero, we cannot reject the null. \n\nWe can reconstruct the figure above using this logic. Rather than plot the points continuously along the x-axis, we can color the points (and now error bars) according to whether the lower bound falls above zero or not. And we can use a bar plot showing the number of rejections and non-rejections.\n\n\n::: {.cell .column-screen-inset-right hash='index_cache/html/unnamed-chunk-2_773d9060805f2430fb380b75c96c3076'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(gganimate)\nlibrary(magick)\n\n# gif pars\nduration <- 24 # must be even\nfps <- 25\nnframes <- duration*fps\nscale <- 2.5\nwidth <- 8\nheight <- 6\nres <- 125\n\n# study parameters\ntrue_effect <- 1\nse <- 0.4\n\n# number of times to repeat the study\nn_studies <- 50 # nframes\n\n# create a data frame of confidence intervals\nests <- tibble(study_id = 1:n_studies, \n               est = c(rnorm(n_studies, true_effect, se))) %>%\n  mutate(reject_null = ifelse(est - 1.64*se > 0, \"Yes\", \"No\"),\n         lwr = est - 1.64*se,\n         upr = est + 1.64*se)\n\n# add two things to the data frame of confidence intervals\n# 1. an initial row with study_id = 1 and est = NA so that \n#    the plot starts empty (gganimate would start with the \n#    first observation in place otherwise).\n# 2. a group variable that defines the row. This is the same\n#    as the study_id, except the dummy row from (1) and the \n#    actual first row have different groups.\nanimate_data <- bind_rows(\n  tibble(study_id = 1, est = NA),  # study_id = 1, est = NA\n  ests                             # actual cis\n) %>%\n  mutate(group = 1:n()) \n\nsplit_animate_data <- animate_data %>%        # group (row index)\n  split(.$group) %>%\n  accumulate(~ bind_rows(.x, .y)) %>% \n  bind_rows(.id = \"frame\") %>% \n  mutate(frame = as.integer(frame))\n\n\nse_lines <- tribble(\n  ~se_, ~label, ~chance, ~ch_loc_,  # trailing _ means not rescaeld to study se\n  0, \"True Effect\", NA, NA,\n  1, \"+1 SE\", scales::percent(pnorm(1) - pnorm(0), accuracy = 1), 0.5,\n  2, \"+2 SE\", scales::percent(pnorm(2) - pnorm(1), accuracy = 1), 1.5,\n  3, \"+3 SE\", scales::percent(pnorm(3) - pnorm(2), accuracy = 1), 2.5,\n  -1, \"-1 SE\", scales::percent(pnorm(0) - pnorm(-1), accuracy = 1), -0.5,\n  -2, \"-2 SE\", scales::percent(pnorm(-1) - pnorm(-2), accuracy = 1), -1.5,\n  -3, \"-3 SE\", scales::percent(pnorm(-2) - pnorm(-3), accuracy = 1), -2.5,\n) %>%\n  mutate(ch_loc = ch_loc_*se + true_effect,\n         se = se_*se + true_effect)\n\n# start with a ggplot\ngg1 <- ggplot(animate_data, aes(x = est, \n                                y = study_id,\n                                group = group)) + \n  geom_vline(xintercept = 1.64*se) + \n  annotate(\"label\", x = 1.64*se, y = 5, label = \"1.64 SEs\") + \n  geom_errorbarh(height = 0, aes(xmin = lwr, xmax = upr, color = reject_null)) + \n  geom_point(aes(color = reject_null),\n             size = 3) + \n  geom_rug(sides = \"b\", \n           aes(x = est, \n               color = reject_null), \n           alpha = 0.5, \n           length = unit(0.025, \"npc\")) + \n  theme_bw() + \n  theme(panel.grid.minor.y = element_blank()) + \n  labs(x = \"Estimate of Effect\",\n       y = \"Study Number\") +\n  theme(legend.position = \"none\") + \n  scale_color_manual(values = c(\"Yes\" = \"#1b9e77\", \"No\" = \"#d95f02\"))\n\n# add dyamics to the plot\ngg1_anim <- gg1 +  \n  transition_states(states = group) + \n  # how points enter\n  enter_drift(y_mod = 10) +\n  enter_grow() +\n  enter_fade() + \n  # how points exit/remain\n  exit_fade(alpha = 0.5) +\n  exit_shrink(size = 1) + \n  shadow_mark(alpha = 0.5) \n\ngg1_gif<- animate(gg1_anim, nframes = nframes, duration = duration, width = width, height = height, units = \"in\", res = res)\nanim_save(\"gg1.gif\")\ngg1_mgif <- image_read(\"gg1.gif\")\n\n\n## plot 2: histogram\n# start with a ggplot\ngg2 <- ggplot(split_animate_data, aes(x = reject_null, fill = reject_null),  na.rm = TRUE) + \n  geom_bar(na.rm = TRUE) + \n  theme_bw() + \n  labs(x = \"Reject Null\",\n       y = \"Count\") + \n  theme(legend.position = \"none\") + \n  scale_x_discrete(na.translate = FALSE) + \n  scale_fill_manual(values = c(\"Yes\" = \"#1b9e77\", \"No\" = \"#d95f02\"))\n\n# add dyamics to the plot\ngg2_anim <- gg2 +  \n  transition_states(states = frame)\n\ngg2_gif<- animate(gg2_anim, nframes = nframes, duration = duration, width = width, height = height, units = \"in\", res = res)\nanim_save(\"gg2.gif\")\ngg2_mgif <- image_read(\"gg2.gif\")\n\n\n\nnew_gif <- image_append(c(gg1_mgif[1], gg2_mgif[1]), stack = FALSE)\nfor(i in 2:nframes){\n  combined_gif <- image_append(c(gg1_mgif[i], gg2_mgif[i]), stack = FALSE)\n  new_gif <- c(new_gif, combined_gif)\n}\nnew_gif\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.gif)\n:::\n\n```{.r .cell-code}\nfile.remove(\"gg1.gif\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nfile.remove(\"gg2.gif\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\n## The Key Ratio\n\nThe key to building statistical power into your experiment is to get \"almost all\" of the sampling distribution above 1.64 standard errors above zero. The portion of the sampling distribution that falls below 1.64 standard errors above zero does not allow the researcher to reject the null.\n\n\n::: {.cell .column-screen-inset-right hash='index_cache/html/unnamed-chunk-3_ae148b7ae499c1f0d3d536545760eb36'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# study parameters\ntrue_effect <- 1\nse <- 0.4\n\n\nse_lines <- tribble(\n  ~se_, ~label, ~chance, ~ch_loc_,  # trailing _ means not rescaeld to study se\n  0, \"True Effect\", NA, NA,\n  1, \"+1 SE\", scales::percent(pnorm(1) - pnorm(0), accuracy = 1), 0.5,\n  2, \"+2 SE\", scales::percent(pnorm(2) - pnorm(1), accuracy = 1), 1.5,\n  3, \"+3 SE\", scales::percent(pnorm(3) - pnorm(2), accuracy = 1), 2.5,\n  -1, \"-1 SE\", scales::percent(pnorm(0) - pnorm(-1), accuracy = 1), -0.5,\n  -2, \"-2 SE\", scales::percent(pnorm(-1) - pnorm(-2), accuracy = 1), -1.5,\n  -3, \"-3 SE\", scales::percent(pnorm(-2) - pnorm(-3), accuracy = 1), -2.5,\n) %>%\n  mutate(ch_loc = ch_loc_*se + true_effect,\n         se = se_*se + true_effect) \n\nx <- rnorm(500000, mean = true_effect, sd = se)\ndf <- data.frame(x)\n\nbg_alpha <- 0.3\nggplot() + \n  geom_histogram(data = df, \n                 aes(x = x, y = after_stat(density)), binwidth = se, boundary = true_effect, fill = \"grey\", alpha = bg_alpha) + \n  geom_vline(data = se_lines, aes(xintercept = se, \n                                  color = -dnorm(se_)), linetype = \"dashed\", alpha = bg_alpha) + \n  geom_label(data = se_lines, aes(x = se, y = Inf, label = label, group = NULL), vjust = 1.5, color = alpha('black', bg_alpha)) + \n  geom_label(data = se_lines, aes(x = ch_loc, y = 0, label = chance, group = NULL), vjust = -1, color = alpha('black', bg_alpha)) + \n  geom_vline(xintercept = 0) + \n  geom_function(fun = dnorm, args = list(mean = true_effect, sd = se), size = 1) + \n  theme_bw() + \n  labs(x = \"Estimate of Effect\",\n       y = \"Density\") + \n  geom_area(data = tibble(x = seq(1.64*se, 3*se + true_effect, by = 0.1)), aes(x = x), \n            stat = \"function\", fun = dnorm, args = list(mean = true_effect, sd = se),\n            fill = \"#d95f02\", alpha = 0.1, xlim = c(1.64*se, 3**se + true_effect)) + \n  annotate(\"label\", x = 1.3, y = .1, label = \"fraction rejected\", color = \"#d95f02\", size = 6) +\n  annotate(\"segment\", x = 1.64*se, xend = 1.64*se, y = 0, yend = dnorm(1.64*se, mean = true_effect, sd = se), color = \"#1b9e77\", size = 1) + \n  annotate(\"label\", x = 1.64*se, y = dnorm(1.64*se, mean = true_effect, sd = se)/2, label = \"1.64 SEs above zero\", color = \"#1b9e77\") + \n  annotate(\"segment\", x = 0, xend = 1.64*se, \n           y = dnorm(1.64*se, mean = true_effect, sd = se), \n           yend = dnorm(1.64*se, mean = true_effect, sd = se), \n           color = \"#7570b3\", size = 1) + \n  annotate(\"label\", x = 0.5*1.64*se, y = dnorm(1.64*se, mean = true_effect, sd = se), label = \"width of 90% CI\", color = \"#7570b3\") + \n  theme(legend.position = \"none\") + \n  xlim(-1, 3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\nYou'll remember that \"almost all\" of the normal distribution falls within two standard errors of its mean. So as a starting point, let's use this rule: get the sampling distribution two standard errors above 1.64 standard errors above zero. We can just add 1.64 and 2 together to get a sampling distribution 3.64 standard errors above zero. That is, we need $\\frac{\\text{true effect}}{\\text{standard error}} > 3.64$. If the true effect is larger than 3.64 standard errors, then the confidence interval will \"rarely\" overlap zero (about 2% of the time). \n\n\n::: {.cell .column-screen-inset-right hash='index_cache/html/unnamed-chunk-4_a91efc73b8d2befdc4dcd25504202cf9'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# study parameters\ntrue_effect <- 1\nse <- 1/3.84\n\nx <- rnorm(500000, mean = true_effect, sd = se)\ndf <- data.frame(x)\n\nggplot() + \n  geom_histogram(data = df, \n                 aes(x = x, y = after_stat(density)), binwidth = se, boundary = true_effect, fill = \"grey\", alpha = bg_alpha) + \n  geom_vline(data = se_lines, aes(xintercept = se, \n                                  color = -dnorm(se_)), linetype = \"dashed\", alpha = bg_alpha) + \n  geom_label(data = se_lines, aes(x = se, y = Inf, label = label, group = NULL), vjust = 1.5, color = alpha('black', bg_alpha)) + \n  geom_label(data = se_lines, aes(x = ch_loc, y = 0, label = chance, group = NULL), vjust = -1, color = alpha('black', bg_alpha)) + \n  geom_vline(xintercept = 0) + \n  geom_function(fun = dnorm, args = list(mean = true_effect, sd = se), size = 1) + \n  theme_bw() + \n  labs(x = \"Estimate of Effect\",\n       y = \"Density\") + \n  geom_area(data = tibble(x = seq(1.64*se, 3*se + true_effect, by = 0.1)), aes(x = x), \n            stat = \"function\", fun = dnorm, args = list(mean = true_effect, sd = se),\n            fill = \"#d95f02\", alpha = 0.1, xlim = c(1.64*se, 3**se + true_effect)) + \n  #annotate(\"label\", x = 1.3, y = .1, label = \"fraction rejected\", color = \"#d95f02\", size = 6) +\n  annotate(\"segment\", x = true_effect, xend = true_effect, y = 0, yend = dnorm(true_effect, mean = true_effect, sd = se), color = \"#d95f02\", size = 1) + \n  annotate(\"label\", x = true_effect, y = dnorm(true_effect, mean = true_effect, sd = se)/2, label = \"true effect\", color = \"#d95f02\") +   \n  annotate(\"segment\", x = 1.64*se, xend = 1.64*se, y = 0, yend = .75, color = \"#1b9e77\", size = 1) + \n  annotate(\"label\", x = 1.64*se, y = .75, label = \"1.64 SEs above zero\", color = \"#1b9e77\") + \n  annotate(\"segment\", x = 0, xend = 1.64*se, \n           y = .125, \n           yend = .125, \n           color = \"#7570b3\", size = 1,\n           lineend = \"round\", linejoin = \"round\", arrow = arrow(length = unit(0.1, \"inches\"), ends = \"both\")) + \n  annotate(\"label\", x = 0.5*1.64*se, y = .125, label = \"1.64 SEs\", color = \"#7570b3\", size = 4) + \n  annotate(\"segment\", x = true_effect, xend = 1.64*se, \n           y = .125, \n           yend = .125, \n           color = \"black\", size = 1,\n           lineend = \"round\", linejoin = \"round\", arrow = arrow(length = unit(0.1, \"inches\"), ends = \"both\")) + \n  annotate(\"label\", x = 1.64*se + (true_effect - 1.64*se)/2, y = .125\n  \n  , label = \"ideally 2 SEs\", color = \"black\", size = 4) + \n  annotate(\"segment\", x = true_effect, xend = 0, \n           y = 1, yend = 1, \n           color = \"black\", size = 1,\n           lineend = \"round\", linejoin = \"round\", arrow = arrow(length = unit(0.1, \"inches\"), ends = \"both\")) + \n  annotate(\"label\", x = true_effect/2, y = 1, label = \"ideally 3.64 SEs\", color = \"black\", size = 4) + \n  theme(legend.position = \"none\") + \n  xlim(-0.1, 2.0)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n## The Resulting Guidelines\n\nThere are a few ways to write the ratio:\n\n1. $\\frac{\\text{true effect}}{\\text{standard error}} > 3.64$\n1. $\\text{true effect} > 3.64 \\times \\text{standard error}$\n1. $\\text{standard error} < \\frac{1}{3.64} \\times \\text{true effect} \\approx 0.27 \\times \\text{true effect}$\n\nThese are all the same goals. I prefer the first, but they are all equivalent targets for power. \n\nI like this ratio because it points to *strategies* to increase power. You can do two things:\n\n1. Increase the true effect.\n2. Decrease the standard error.\n\nThis ratio gets you thinking not *what* your power is, but *how to increase it*. Again, power isn't *a* task for the experimenter, it's *the* task.^[I'm leaving aside the question of how to predict the standard error or choose a true effect for a paricular design.] [Kane (2023)](https://doi.org/10.33774/apsa-2023-h4p0q-v2)^[Kane, John V. 2023. \"More Than Meets the ITT:  A Guide for Investigating Null Results.\" APSA Preprints. [doi: 10.33774/apsa-2023-h4p0q-v2](https://doi.org/10.33774/apsa-2023-h4p0q-v2).] suggests several ways researchers can increase the true effect or decrease the standard error.\n\nI'll highlight a few examples here. To increase the treatment effect, you can:\n\n1. Increase attentiveness.\n1. Ensure that respondents are not pre-treated.\n1. Write strong treatments or \"hit them between the eyes\" [(Kuklinski *et al.* 2000)](https://www.jstor.org/stable/2647960).\n\nTo decrease the standard error, you can:\n\n1. Increase the sample size.\n2. Use multiple measurements for the outcome.\n3. Use a pre-post design [(Clifford, Sheagley, and Piston 2022)](https://doi.org/10.1017/S0003055421000241).\n\n## Implication\n\nIf you get the ratio to 3.64, then you'll have 98%. This is much higher than the cutoff of 80% I hear suggested most often. If you want 80% power, rather than 98% power, you can change the 3.64 to 2.48.^[Find this by adding 1.64 to `-qnorm(0.2)`.] But notice that 3.64 and 2.48 are not very different. This has an important implication.\n\nA researcher can lower the risk of a failed study from about 1 in 5 (80% power) to about 1 in 50 (98% power) by increasing the ratio from 2.48 to 3.64. This requires increasing the treatment effect by about 50% or shrinking the standard error by about 33%. Stated differently, if you are careless and let your treatment effect fall by 33% or let your standard error increase by 50%, then your risk of a failed study increases 10-fold! Small differences can matter a lot.\n\nThe implication is this: when you are on the cusp of a well-powered study (about 80% power), then small increases in the ratio have a disproportionate impact on your risk of a failed study.\n\n## Computing Power from the Ratio\n\nFollowing the logic of the picture above, we need to compute the fraction of the sampling distributin that lies above 1.64 SEs. The `pnorm()` function returns normal probabilities, but *below* specfic thresholds. By supplying the argument `lower.tail = FALSE`, we can get the probabilities of falling *above* a specific threshold. \n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_d9afb3bbe1456ba18f58ca7b98720c3e'}\n\n```{.r .cell-code  code-fold=\"false\"}\ntrue_effect <- 1.00\nse <- 0.4\n\n# compute power\npnorm(1.64*se,   # want fraction above 1.64 SE\n      mean = true_effect,  # mean of sampling distribution\n      sd = se,  # sd of sampling distribution\n      lower.tail = FALSE)  # fraction above, not below\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8051055\n```\n:::\n:::\n\n\n## Summary\n\nStatistical power is an abstract quantity. It's easy to understand what it means, but harder to think about how to manipulate it. I explain why the target $\\frac{\\text{true effect}}{\\text{standard error}} > 2.48$ is equivalent to a target power of 80%. But you want to \"almost always\" reject the null, so you should shoot for $\\frac{\\text{true effect}}{\\text{standard error}} > 3.64$. Hopefully these guidelines help you build a bit of actionable intuition about statistical power.\n\nIf you found this fun or useful, don't forget subscribe! ðŸš€ \n\n\n```{=html}\n<!-- MailerLite Universal -->\n<script>\n    (function(w,d,e,u,f,l,n){w[f]=w[f]||function(){(w[f].q=w[f].q||[])\n    .push(arguments);},l=d.createElement(e),l.async=1,l.src=u,\n    n=d.getElementsByTagName(e)[0],n.parentNode.insertBefore(l,n);})\n    (window,document,'script','https://assets.mailerlite.com/js/universal.js','ml');\n    ml('account', '438589');\n</script>\n<!-- End MailerLite Universal -->\n```\n\n<div class=\"ml-embedded\" data-form=\"3lK3qC\"></div>\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}